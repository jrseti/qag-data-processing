{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moon Data Processing Notebook\n",
    "### Beginning the process of processing the QAG Moon bounce data from Sep 10, 2021\n",
    "#### Jon Richards - SETI Institute Quantum Astronomy Group\n",
    "#### This code draws a waterfall plot from the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.fft import fft, fftfreq\n",
    "import scipy.fftpack\n",
    "from scipy.signal import argrelextrema\n",
    "\n",
    "from datetime import datetime as dt\n",
    "\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 15, 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the data file we wish to process\n",
    "data_file_path = \"/Volumes/QAG Disk 1/data/moon_09102021/moon_2021-09-10T22_19_57.781495_1y\"\n",
    "#data_file_path = \"/Volumes/QAG Backup/data/moon_09102021/moon_2021-09-10T22_19_57.781495_0x\"\n",
    "#data_file_path = \"./data/data_1x\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: seek_by_time() did not return the correct offset. Please check!\n"
     ]
    }
   ],
   "source": [
    "START_TIME = 1631312409.1568253092447917 #This is UTC 2021-09-10 22:20:09\n",
    "SAMPLES_PER_SEC = 1920000\n",
    "BYTES_PER_SAMPLE = 4\n",
    "SECS_OFFSET = 3\n",
    "\n",
    "def seek_by_time(file, datetime_str):\n",
    "    \"\"\"Find the offset into the file for the given datetime and seek.\n",
    "    Arguments:\n",
    "        file - the open file\n",
    "        datetime_str - A datetime in the form 2021-09-10 22:20:09, this if UTC\n",
    "    Returns:\n",
    "        int - the bytes skipped in the file.\n",
    "    \"\"\"\n",
    "    d_start = dt.strptime(\"2021-09-10 22:20:09\", '%Y-%m-%d %H:%M:%S') \n",
    "    d = dt.strptime(datetime_str, '%Y-%m-%d %H:%M:%S') \n",
    "    diff_secs = int(dt.timestamp(d) - dt.timestamp(d_start)) + SECS_OFFSET\n",
    "\n",
    "    bytes_to_skip = diff_secs * SAMPLES_PER_SEC * BYTES_PER_SAMPLE\n",
    "    \n",
    "    #print(bytes_to_skip)\n",
    "    \n",
    "    if file != None:\n",
    "        file.seek(bytes_to_skip)\n",
    "    \n",
    "    return bytes_to_skip\n",
    "\n",
    "if seek_by_time(None, \"2021-09-10 22:20:10\")  != 7680000:\n",
    "    print(\"WARNING: seek_by_time() did not return the correct offset. Please check!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readBlock(file, num_samples):\n",
    "    \"\"\" \n",
    "    Read the next FFT sized block of 16-bit I/Q data from an opened file.\n",
    "    \n",
    "    Arguments:\n",
    "        file - The reference to the data file, already opened.\n",
    "        num_samples - The number of 16-bit I/Q samples to read in.\n",
    "            Example, If you FFT SIZE is 1024, the num_samples should\n",
    "            be 1024. 2048 16-bit samples (4096 bytes total) will be \n",
    "            read and unpacked from the file.\n",
    "            \n",
    "        Return - A Numpy array of \"num_samples\" Complex64 values.\n",
    "            None if the read is past the end of the file.\n",
    "    \n",
    "    \"\"\"\n",
    "    # Read the bytes from the file\n",
    "    data_raw = np.fromfile(file, dtype=np.int16, count=num_samples*2)\n",
    "    \n",
    "    # Create a Complex64 Numpy array to hold the values\n",
    "    data = np.zeros((num_samples,), dtype=np.complex64)\n",
    "    \n",
    "    # Reassemble the int16 aray into the Complex64 array.\n",
    "    # Use a try block to catch the condition where the end of the file\n",
    "    # has been passed.\n",
    "    try:\n",
    "        data[:] = (data_raw[0::2]) + 1j*(data_raw[1::2])\n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calFreqRangeForAxis(center_hz, bw_hz):\n",
    "    \n",
    "    \"\"\"\n",
    "    For the X axis tick mark labels, calculate the frequency min/max/center\n",
    "    \n",
    "    Arguments:\n",
    "        center_hz - The center frequency of the signal, in Hertz.\n",
    "        bw_hz - The bandwidth of the signal, in Hertz.\n",
    "        \n",
    "    Returns - A tuple of the \n",
    "        min frequency od the signal, in MHz\n",
    "        max frequency od the signal, in MHz\n",
    "        center frequency od the signal, in MHz\n",
    "        \n",
    "    \"\"\"\n",
    "    min_hz = center_hz - bw_hz/2.0\n",
    "    max_hz = center_hz + bw_hz/2.0\n",
    "    \n",
    "    return (min_hz/1000000.0, max_hz/1000000., center_hz/1000000.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_waterfall(filename, title1, title2, datetime_str, num_secs, start_chan, end_chan, output_image_name=None):\n",
    "    \n",
    "    \"\"\"Create a waterfall plot\n",
    "    Arguments:\n",
    "        filename - The full path filename\n",
    "        datetime_str - the time offset into the file\n",
    "        num_secs - number of seconds to process\n",
    "        start_chan - the start frequency bin\n",
    "        end_chan - the end frequency bin\n",
    "        output_image_name- Optional, save an image of the plot\n",
    "    \"\"\"\n",
    "    \n",
    "    # Perform the FFT and store the result for later plotting.\n",
    "    # The FFT result will be accumulated in a one dimensional Numpy array\n",
    "    # of length equal to the FFT_SIZE\n",
    "\n",
    "    # Define some constants. Here you may wish to change the FFT_SIZE\n",
    "    FFT_SIZE = 1960000\n",
    "    CENTER_FREQ_HZ = 1296000000\n",
    "    BANDWIDTH_HZ   = 1920000\n",
    "    MHZ = 1048576.0\n",
    "    NUM_CHANS = end_chan - start_chan\n",
    "\n",
    "    # Create an array to hold the data for each horizontal line of the waterfall\n",
    "    bins = []\n",
    "\n",
    "    # How many FFT_SIZE chunks to process. Ideally we would like to\n",
    "    # process the entire channel, but during code development we may\n",
    "    # wish to read in a smaller number. Reading in the large data files\n",
    "    # takes a lot of time.\n",
    "    NUM = num_secs\n",
    "\n",
    "    # Open the file\n",
    "    file = open(filename, \"rb\")\n",
    "\n",
    "    # Seek\n",
    "    seek_by_time(file, datetime_str)\n",
    "    \n",
    "    # Create an array to hold the accumulation for each bin\n",
    "    fft_acc = np.zeros((end_chan - start_chan, ))\n",
    "\n",
    "    # Keep a counter of the number of FFT_SIZE length chunks we processed.\n",
    "    count = 0\n",
    "\n",
    "    # Loop through the file. \n",
    "    for i in range(NUM):\n",
    "\n",
    "        #print(i)\n",
    "\n",
    "        # Read the next block of data from the file\n",
    "        d = readBlock(file, FFT_SIZE)\n",
    "\n",
    "        # If None is retruned, this signifies we read to the end of the file.\n",
    "        # Break out of the loop.\n",
    "        if d is None:\n",
    "            print(\"d is NONE\")\n",
    "            break\n",
    "\n",
    "        yf = scipy.fftpack.fft(d, n=FFT_SIZE, axis=0)\n",
    "        \n",
    "        #Add the results of the FFTp to the fft_acc Numpy array\n",
    "        np.add(np.abs(yf[start_chan:end_chan]), fft_acc, out=fft_acc)\n",
    "        \n",
    "        #print(np.abs(yf[start_chan:start_chan+1]), fft_acc[0:1])\n",
    "        \n",
    "        xx = np.abs(yf).tolist()\n",
    "        yy = scipy.fft.fftshift(xx)\n",
    "        bins.append(yy[start_chan:end_chan])\n",
    "        \n",
    "        \n",
    "\n",
    "        # Draw a plot of the results\n",
    "\n",
    "    fig, ax = plt.subplots(1,2)\n",
    "    #fig, ax = plt.subplots(1,2,figsize=(72/8, 60/4))\n",
    "\n",
    "    #ax.set_ylim(0, 40)\n",
    "\n",
    "    ax[0].imshow(bins)\n",
    "    \n",
    "    fig.suptitle(title1, fontsize=18)\n",
    "    ax[0].set_title(title2)\n",
    "    \n",
    "    # Make the Y axis be log\n",
    "    ax[1].set_yscale('log')\n",
    "    \n",
    "    # A strange artifact of the FFTp process is that the upper and lower\n",
    "    # halved are swapped. The fftshift swaps them back to the correct order.\n",
    "    fft_acc_temp = scipy.fft.fftshift(fft_acc) \n",
    "    fft_acc = fft_acc_temp\n",
    "    \n",
    "    chan_min_freq_mhz = (CENTER_FREQ_HZ - 1236524.0)/MHZ\n",
    "    \n",
    "    freqs_for_xaxis = [(chan_min_freq_mhz + (f*(BANDWIDTH_HZ/FFT_SIZE))/MHZ) for f in range(NUM_CHANS)]\n",
    "\n",
    "    ax[1].plot(freqs_for_xaxis, fft_acc)\n",
    "\n",
    "\n",
    "    if output_image_name != None:\n",
    "        plt.savefig(output_image_name)\n",
    "        \n",
    "    # Show!\n",
    "    #plt.show()\n",
    "    plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_waterfall(data_file_path, \"3, -3\", \"  \", \"2021-09-10 23:05:00\", 60, 1236524, 1236622, \"test5\")\n",
    "#create_waterfall(data_file_path, \"2021-09-10 22:24:00\", 4*60, 1200000, 1250000, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(bins[119]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n"
     ]
    }
   ],
   "source": [
    "# Create a list of the schedue\n",
    "schedule = []\n",
    "\n",
    "schedule.append([-3,3,'2021-09-10 23:05:00'])\n",
    "schedule.append([-6,6,'2021-09-10 23:07:00'])\n",
    "schedule.append([-9,9,'2021-09-10 23:09:00'])\n",
    "schedule.append([-10,10,'2021-09-10 23:11:00'])\n",
    "schedule.append([-11,11,'2021-09-10 23:13:00'])\n",
    "schedule.append([-13,13,'2021-09-10 23:15:00'])\n",
    "schedule.append([-3,6,'2021-09-10 23:17:00'])\n",
    "schedule.append([-3,9,'2021-09-10 23:19:00'])\n",
    "schedule.append([-3,10,'2021-09-10 23:21:00'])\n",
    "schedule.append([-3,11,'2021-09-10 23:23:00'])\n",
    "schedule.append([-3,13,'2021-09-10 23:25:00'])\n",
    "schedule.append([-6,3,'2021-09-10 23:27:00'])\n",
    "schedule.append([-6,9,'2021-09-10 23:29:00'])\n",
    "schedule.append([-6,10,'2021-09-10 23:31:00'])\n",
    "schedule.append([-6,11,'2021-09-10 23:33:00'])\n",
    "schedule.append([-6,13,'2021-09-10 23:35:00'])\n",
    "schedule.append([-9,3,'2021-09-10 23:37:00'])\n",
    "schedule.append([-9,6,'2021-09-10 23:39:00'])\n",
    "schedule.append([-9,10,'2021-09-10 23:41:00'])\n",
    "schedule.append([-9,11,'2021-09-10 23:43:00'])\n",
    "schedule.append([-9,13,'2021-09-10 23:45:00'])\n",
    "schedule.append([-10,3,'2021-09-10 23:47:00'])\n",
    "schedule.append([-10,6,'2021-09-10 23:49:00'])\n",
    "schedule.append([-10,9,'2021-09-10 23:51:00'])\n",
    "schedule.append([-10,11,'2021-09-10 23:53:00'])\n",
    "schedule.append([-10,13,'2021-09-10 23:55:00'])\n",
    "schedule.append([-11,3,'2021-09-10 23:57:00'])\n",
    "schedule.append([-11,6,'2021-09-10 23:59:00'])\n",
    "schedule.append([-11,9,'2021-09-11 00:01:00'])\n",
    "schedule.append([-11,10,'2021-09-11 00:03:00'])\n",
    "schedule.append([-11,13,'2021-09-11 00:05:00'])\n",
    "schedule.append([-13,3,'2021-09-11 00:07:00'])\n",
    "schedule.append([-13,6,'2021-09-11 00:09:00'])\n",
    "schedule.append([-13,9,'2021-09-11 00:11:00'])\n",
    "schedule.append([-13,10,'2021-09-11 00:13:00'])\n",
    "schedule.append([-13,11,'2021-09-11 00:15:00'])\n",
    "schedule.append([-10,10,'2021-09-11 00:17:00'])\n",
    "schedule.append([-9,9,'2021-09-11 00:19:00'])\n",
    "schedule.append([-8,8,'2021-09-11 00:21:00'])\n",
    "\n",
    "#print(schedule)\n",
    "print(len(schedule))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "-3, 3 images/offsets_-3,3_t20210910230500\n",
      "2\n",
      "-6, 6 images/offsets_-6,6_t20210910230700\n",
      "3\n",
      "-9, 9 images/offsets_-9,9_t20210910230900\n",
      "4\n",
      "-10, 10 images/offsets_-10,10_t20210910231100\n",
      "5\n",
      "-11, 11 images/offsets_-11,11_t20210910231300\n",
      "6\n",
      "-13, 13 images/offsets_-13,13_t20210910231500\n",
      "7\n",
      "-3, 6 images/offsets_-3,6_t20210910231700\n",
      "8\n",
      "-3, 9 images/offsets_-3,9_t20210910231900\n",
      "9\n",
      "-3, 10 images/offsets_-3,10_t20210910232100\n",
      "10\n",
      "-3, 11 images/offsets_-3,11_t20210910232300\n",
      "11\n",
      "-3, 13 images/offsets_-3,13_t20210910232500\n",
      "12\n",
      "-6, 3 images/offsets_-6,3_t20210910232700\n",
      "13\n",
      "-6, 9 images/offsets_-6,9_t20210910232900\n",
      "14\n",
      "-6, 10 images/offsets_-6,10_t20210910233100\n",
      "15\n",
      "-6, 11 images/offsets_-6,11_t20210910233300\n",
      "16\n",
      "-6, 13 images/offsets_-6,13_t20210910233500\n",
      "17\n",
      "-9, 3 images/offsets_-9,3_t20210910233700\n",
      "18\n",
      "-9, 6 images/offsets_-9,6_t20210910233900\n",
      "19\n",
      "-9, 10 images/offsets_-9,10_t20210910234100\n",
      "20\n",
      "-9, 11 images/offsets_-9,11_t20210910234300\n",
      "21\n",
      "-9, 13 images/offsets_-9,13_t20210910234500\n",
      "22\n",
      "-10, 3 images/offsets_-10,3_t20210910234700\n",
      "23\n",
      "-10, 6 images/offsets_-10,6_t20210910234900\n",
      "24\n",
      "-10, 9 images/offsets_-10,9_t20210910235100\n",
      "25\n",
      "-10, 11 images/offsets_-10,11_t20210910235300\n",
      "26\n",
      "-10, 13 images/offsets_-10,13_t20210910235500\n",
      "27\n",
      "-11, 3 images/offsets_-11,3_t20210910235700\n",
      "28\n",
      "-11, 6 images/offsets_-11,6_t20210910235900\n",
      "29\n",
      "-11, 9 images/offsets_-11,9_t20210911000100\n",
      "30\n",
      "-11, 10 images/offsets_-11,10_t20210911000300\n",
      "31\n",
      "-11, 13 images/offsets_-11,13_t20210911000500\n",
      "32\n",
      "-13, 3 images/offsets_-13,3_t20210911000700\n",
      "33\n",
      "-13, 6 images/offsets_-13,6_t20210911000900\n",
      "34\n",
      "-13, 9 images/offsets_-13,9_t20210911001100\n",
      "35\n",
      "-13, 10 images/offsets_-13,10_t20210911001300\n",
      "36\n",
      "-13, 11 images/offsets_-13,11_t20210911001500\n",
      "37\n",
      "-10, 10 images/offsets_-10,10_t20210911001700\n",
      "38\n",
      "-9, 9 images/offsets_-9,9_t20210911001900\n",
      "39\n",
      "-8, 8 images/offsets_-8,8_t20210911002100\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for sched in schedule:\n",
    "    \n",
    "    count = count + 1\n",
    "    print(count)\n",
    "    \n",
    "    offset1 = sched[0]\n",
    "    offset2 = sched[1]\n",
    "    d = sched[2]\n",
    "    \n",
    "    title = f\"{offset1}, {offset2}\"\n",
    "    filename = f\"images/offsets_{offset1},{offset2}_t{d.replace(':', '').replace(' ','').replace('-', '')}\"\n",
    "    print(title, filename)\n",
    "    create_waterfall(data_file_path, title, \"  \", d, 60, 1236524, 1236622, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
